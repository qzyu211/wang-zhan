---
title: "Matrix Notation"
date: 2019-10-18
tags: [statistics, machine-learning, linear-algebra]
excerpt: "Understand the matrix notation used on this website."
category: statistics
mathjax: "true"
---
In this post, the common matrix notation used on this website will be thoroughly explained. The importance for learning how to understand the matrix representation is so that it's possible to follow along step-by-step the meaning of the various formulas.

1. [The Benefit of Matrix Representation](https://qzyu999.github.io/wang-zhan/statistics/notation/#the-benefit-of-matrix-representation)
2. [The Style of Notation Used on this Website](https://qzyu999.github.io/wang-zhan/statistics/notation/#the-style-of-notation-used-on-this-website)
3. [Extensions from Univariate to Multivariate](https://qzyu999.github.io/wang-zhan/statistics/notation/#extensions-from-univariate-to-multivariate)
4. [Applications of the Matrix Format](https://qzyu999.github.io/wang-zhan/statistics/notation/#applications-of-the-matrix-format)

## The Benefit of Matrix Representation
The usefulness of matrix representation will be expressed briefly. Within introductory statistical courses, the univariate (data with one variable, e.g., height) is explored and different types of statistical inference are briefly covered. However, in order to extend these analysis to data with multivariate (data with more than one variable, e.g., height and weight) properties, it's possible to retain the same tools of analysis, with the exception that data and calculations are done using matrices.

Also, it is important to understand the style of notation used anytime it is necessary to look closely at a formula. Different authors utilize different styles of matrix notation, but they all are fine as long as the same style is used throughout the formula.

## The Style of Notation Used on this Website
For the remainder of the page, it will be assumed that basic linear algebra has already been learned (if you have not learned or need to review, please visit [Khan Academy](https://www.khanacademy.org/math/linear-algebra)).

In multivariate statistics, the way that matrix notation is used is that vectors are expressed as follows. Consider the $$n \times p$$ data matrix, $$\textbf{X}$$ (bold-faced, upper-case, non-italicized, Roman letter X), it can be visualized below,

$$\begin{bmatrix}
x_{1,1} & x_{1,2} & \cdots & x_{1,p} \\
x_{2,1} & x_{2,2} & \cdots & x_{2,p} \\
\vdots & \vdots & \ddots & \vdots \\
x_{n,1} & x_{n,2} & \cdots & x_{n,p}
\end{bmatrix}.$$

Each row of the matrix $$\textbf{X}$$ can be thought of as an observation from a dataset. Then each column corresponds to a variable of the observation. Then in the matrix there are $$n$$ observations and $$p$$ variables.

Let us then look at the first observation from the data matrix, $$\vec{x}_1$$ (lower-case, italicized, Roman letter x, with a subscript 1, and a right arrow above). It is a $$p\times 1$$ vector and can be seen below,

$$\begin{bmatrix}
x_{1,1}\\
x_{1,2}\\
\vdots\\
x_{1,p}
\end{bmatrix}.$$

If you notice, the vector is represented vertically, which is an important nuance. Therefore, to visualize the same vector horizontally, the transpose must first be taken. Such a vector can be denoted as $$\vec{x}_1^\top$$. Then it also follows that the data matrix $$\textbf{X}$$ can also be represented as follows,

$$
\begin{bmatrix}
\vec{x}_1^\top\\
\vec{x}_2^\top\\
\vdots\\
\vec{x}_n^\top
\end{bmatrix}.
$$

Now, let us look back at a single observation, $$x_{i,j}$$ (lower-case, italicized, Roman letter x with a subscript i and j). The subscripts indicate the $$ith$$ row and $$jth$$ column. Therefore, the second variable of the first observation can be referenced by $$x_{1,2}$$. The letters $$i$$ and $$j$$ are dummy variables, which implies that they can be changed to something else such as $$k$$ and $$l$$.

## Extensions from Univariate to Multivariate
In the univariate case, we are all familiar with learning that the variance of a set of numbers is denoted as $$\sigma^2$$. Take for example, the vector, $\vec{x}^\top = [1, 2, 3, 4, 5]$. The variance of the vector can be written as $Var(\vec{x}) = 2.5$. However, if we were to look towards more complicated data, such as a data matrix $$\textbf{X}$$, with $$n$$ rows and $$p$$ observations, then to find the variance of $$\textbf{X}$$ would require looking at $$Var(\textbf{X})$$. This can also be denoted as $$\textbf{\Sigma}$$ (bold-faced, upper-case, Greek-letter Sigma), and is seen below,

$$\begin{bmatrix}
\sigma_{1,1} & \sigma_{1,2} & \cdots & \sigma_{1,p} \\
\sigma_{2,1} & \sigma_{2,2} & \cdots & \sigma_{2,p} \\
\vdots & \vdots & \ddots & \vdots \\
\sigma_{p,1} & \sigma_{p,2} & \cdots & \sigma_{p,p}
\end{bmatrix}.$$

The matrix is known as the variance-covariance matrix and makes it possible to extend analysis from univariate data to multivariate data. The notation $$\sigma_{1,2}$$ denotes the covariance between the first and second variables,

$$

$$

## Applications of the Matrix Format

References:

[1] Applied Multivariate Statistical Analysis 6th Ed., Johnson, Wichern

[2] https://en.wikipedia.org/wiki/Matrix_(mathematics)

[3] https://stattrek.com/matrix-algebra/matrix-notation.aspx
